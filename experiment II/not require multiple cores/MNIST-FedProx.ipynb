{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "manualSeed = 1\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 100\n",
    "DATASIZE_LOCAL = int(60000/DEVICE_NUM)\n",
    "SERVER_NUM = 10\n",
    "DEVICE_PER_SERVER = int(DEVICE_NUM/SERVER_NUM)\n",
    "BATCH_SIZE = 32\n",
    "STEP_NUM = 5\n",
    "LABEL_DIVERSITY = 6\n",
    "ACTIVE_PER_SERVER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "# generate non-IID datasets stored on edge devices\n",
    "trainset = torchvision.datasets.MNIST('.data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "testset = torchvision.datasets.MNIST('.data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "trainloader = []\n",
    "testloader_sub = []\n",
    "for device_ID in range(DEVICE_NUM):\n",
    "    label_set = random.sample(range(0, 10), LABEL_DIVERSITY)\n",
    "    idx = trainset.targets.clone().detach() == label_set[0]\n",
    "    for label_val in label_set[1:]:\n",
    "        idx += trainset.targets.clone().detach() == label_val\n",
    "    indx = np.random.permutation(np.where(idx==1)[0])[0:DATASIZE_LOCAL]\n",
    "    trainset_indx = torch.utils.data.Subset(trainset, indx)\n",
    "    trainloader.append(torch.utils.data.DataLoader(trainset_indx, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2))\n",
    "    idx = testset.targets.clone().detach() == label_set[0]\n",
    "    for label_val in label_set[1:]:\n",
    "        idx += testset.targets.clone().detach() == label_val\n",
    "    test_indx = torch.utils.data.Subset(testset, np.where(idx==1)[0])\n",
    "    testloader_sub.append(torch.utils.data.DataLoader(test_indx, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2))\n",
    "    \n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_state_dic(para_set):\n",
    "    para_copy = copy.deepcopy(para_set)\n",
    "    N = float(len(para_copy))\n",
    "    return { k : sum(t[k] for t in para_copy)/N for k in para_copy[0] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "net = nn.Sequential(  nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "net_const = nn.Sequential(  nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "for p in net_const.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "if torch.cuda.device_count() != 0:\n",
    "    global gpu_dtype\n",
    "    gpu_dtype = torch.cuda.FloatTensor\n",
    "    \n",
    "    net.cuda()\n",
    "    net = net.type(gpu_dtype)\n",
    "    \n",
    "    net_const.cuda()\n",
    "    net_const = net_const.type(gpu_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = net.state_dict()\n",
    "para_set = []\n",
    "\n",
    "# for each edge device, save a copy of the model\n",
    "for i in range(DEVICE_NUM):\n",
    "    para_set.append(copy.deepcopy(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedProx - RHO: 0, training for 250 epochs with learning rate 0.005000\n",
      "Starting epoch 1 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-2b60bba48160>\", line 31, in <module>\n",
      "    for i, data in enumerate(trainloader[device_ID], 0):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 808, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/multiprocessing/connection.py\", line 930, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/inspect.py\", line 744, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "  File \"/Users/Ryan/miniconda3/envs/ryanenv/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 25505) is killed by signal: Unknown signal: 0. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1)\n",
    "learning_rate = 0.005\n",
    "num_epochs = 500\n",
    "RHO = 5\n",
    "runtime_record = 0\n",
    "wake_up_time_server = np.zeros(SERVER_NUM)\n",
    "print('FedProx - RHO: %.1f, training for %d epochs with learning rate %f' % (RHO, num_epochs, learning_rate))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                              momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    print('Starting epoch %d / %d' % (epoch+1, num_epochs))\n",
    "    \n",
    "    # generate the index set of selected edge devices\n",
    "    ACTIVE_DEVICE = []\n",
    "    for server_ID in range(SERVER_NUM):\n",
    "        ACTIVE_DEVICE.append(random.sample(range(server_ID*DEVICE_PER_SERVER, (server_ID+1)*DEVICE_PER_SERVER), ACTIVE_PER_SERVER))\n",
    "    ACTIVE_DEVICE = [item for sublist in ACTIVE_DEVICE for item in sublist]\n",
    "    \n",
    "    # the selected edge devices update their models (edge-device side)\n",
    "    for device_ID in range(DEVICE_NUM):\n",
    "        if device_ID in ACTIVE_DEVICE:\n",
    "            stopping_iter = random.randint(1, STEP_NUM)\n",
    "            net.load_state_dict(para_set[device_ID])\n",
    "            net_const.load_state_dict(copy.deepcopy(para_set[device_ID]))\n",
    "            z_n = list(net_const.parameters())\n",
    "            iter_count = 0\n",
    "            for i, data in enumerate(trainloader[device_ID], 0):\n",
    "                if torch.cuda.device_count() != 0:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                else:\n",
    "                    inputs, labels = data[0], data[1]\n",
    "                inputs = inputs.view(inputs.shape[0], -1)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                datafitting = criterion(outputs, labels)\n",
    "                penalty = None\n",
    "                for (Ww, Zz) in zip(net.parameters(), z_n):\n",
    "                    if penalty is None:\n",
    "                        penalty = torch.norm(Ww-Zz)**2\n",
    "                    else:\n",
    "                        penalty = penalty + torch.norm(Ww-Zz) ** 2\n",
    "                loss = datafitting + RHO * penalty\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                iter_count += 1\n",
    "                if iter_count == stopping_iter:\n",
    "                    break\n",
    "            para_set[device_ID] = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    # aggregate the updated models from the selected edge devices (cloud-server side)\n",
    "    para_update = average_state_dic([para_set[i] for i in ACTIVE_DEVICE])\n",
    "    for i in range(DEVICE_NUM):\n",
    "        para_set[i] = copy.deepcopy(para_update)\n",
    "    \n",
    "    # check the performance on the test dataset\n",
    "    net.load_state_dict(para_update)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            if torch.cuda.device_count() != 0:\n",
    "                images, labels = data[0].cuda(), data[1].cuda()\n",
    "            else:\n",
    "                images, labels = data[0], data[1]\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('[%d, %d] test accuracy: %.2f %%' %  (num_epochs + 1, epoch + 1, 100 * float(correct) / total))\n",
    "        \n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for decive_ID in range(DEVICE_NUM):\n",
    "#         with torch.no_grad():\n",
    "#             for i, data in enumerate(testloader_sub[decive_ID], 0):\n",
    "#                 if torch.cuda.device_count() != 0:\n",
    "#                     images, labels = data[0].cuda(), data[1].cuda()\n",
    "#                 else:\n",
    "#                     images, labels = data[0], data[1]\n",
    "#                 images = images.view(images.shape[0], -1)\n",
    "#                 outputs = net(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#     print('[%d, %d] average device test accuracy: %.2f %%' % (num_epochs + 1, epoch + 1, 100 * float(correct) / total))\n",
    "    \n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for decive_ID in ACTIVE_DEVICE:\n",
    "#         with torch.no_grad():\n",
    "#             for i, data in enumerate(testloader_sub[decive_ID], 0):\n",
    "#                 if torch.cuda.device_count() != 0:\n",
    "#                     images, labels = data[0].cuda(), data[1].cuda()\n",
    "#                 else:\n",
    "#                     images, labels = data[0], data[1]\n",
    "#                 images = images.view(images.shape[0], -1)\n",
    "#                 outputs = net(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#     print('[%d, %d] average selected device test accuracy: %.2f %%' % (num_epochs + 1, epoch + 1, 100 * float(correct) / total))\n",
    "            \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ryanenv)",
   "language": "python",
   "name": "ryanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
