{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from model import ResNet\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import networkx as nx \n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "manualSeed = 1\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_augment = T.Compose([\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomCrop(32, padding=4)])\n",
    "transform_normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 100\n",
    "DATASIZE_LOCAL = int(50000/DEVICE_NUM)\n",
    "SERVER_NUM = 10\n",
    "DEVICE_PER_SERVER = int(DEVICE_NUM/SERVER_NUM)\n",
    "BATCH_SIZE = 32\n",
    "STEP_NUM = 5\n",
    "LABEL_DIVERSITY = 5\n",
    "ACTIVE_PER_SERVER = 3\n",
    "FAULT_RATE = 0.05\n",
    "SYNCHRONIZATION_FLAG = 1\n",
    "CLOUD_STEP_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
    "                                 transform=T.Compose([transform_augment, transform_normalize]))\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_normalize)\n",
    "\n",
    "\n",
    "trainloader = []\n",
    "testloader_sub = []\n",
    "for device_ID in range(DEVICE_NUM):\n",
    "    label_set = random.sample(range(0, 10), LABEL_DIVERSITY)\n",
    "    idx = torch.FloatTensor(trainset.targets) == label_set[0]\n",
    "    for label_val in label_set[1:]:\n",
    "        idx += torch.FloatTensor(trainset.targets) == label_val\n",
    "    indx = np.random.permutation(np.where(idx==1)[0])[0:DATASIZE_LOCAL]\n",
    "    trainset_indx = torch.utils.data.Subset(trainset, indx)\n",
    "    trainloader.append(torch.utils.data.DataLoader(trainset_indx, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2))\n",
    "    idx = torch.FloatTensor(testset.targets) == label_set[0]\n",
    "    for label_val in label_set[1:]:\n",
    "        idx += torch.FloatTensor(testset.targets) == label_val\n",
    "    test_indx = torch.utils.data.Subset(testset, np.where(idx==1)[0])\n",
    "    testloader_sub.append(torch.utils.data.DataLoader(test_indx, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2))\n",
    "    \n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_state_dic(para_set):\n",
    "    para_copy = copy.deepcopy(para_set)\n",
    "    N = float(len(para_copy))\n",
    "    return { k : sum(t[k] for t in para_copy)/N for k in para_copy[0] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(3)\n",
    "\n",
    "if torch.cuda.device_count() != 0:\n",
    "    global gpu_dtype\n",
    "    gpu_dtype = torch.cuda.FloatTensor\n",
    "    \n",
    "    net.cuda()\n",
    "    net = net.type(gpu_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = net.state_dict()\n",
    "para_set = []\n",
    "\n",
    "for i in range(DEVICE_NUM):\n",
    "    para_set.append(copy.deepcopy(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 150 epochs with learning rate 0.025000\n",
      "Starting epoch 1 / 150\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c000588634c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mrunning_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1)\n",
    "learning_rate = 0.005\n",
    "num_epochs = 250\n",
    "print('FedAvg: training for %d epochs with learning rate %f' % (num_epochs, learning_rate))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch %d / %d' % (epoch+1, num_epochs))\n",
    "    start_time = time.time()\n",
    "        \n",
    "    # generate the index set of selected edge devices\n",
    "    ACTIVE_DEVICE = []\n",
    "    for server_ID in range(SERVER_NUM):\n",
    "        ACTIVE_DEVICE.append(random.sample(range(server_ID*DEVICE_PER_SERVER, (server_ID+1)*DEVICE_PER_SERVER), ACTIVE_PER_SERVER))\n",
    "    ACTIVE_DEVICE = [item for sublist in ACTIVE_DEVICE for item in sublist]\n",
    "    \n",
    "    for device_ID in range(DEVICE_NUM):\n",
    "        if device_ID in ACTIVE_DEVICE:\n",
    "            \n",
    "            net.load_state_dict(para_set[device_ID])\n",
    "            stopping_iter = random.randint(1, STEP_NUM)\n",
    "            iter_count = 0\n",
    "            for i, data in enumerate(trainloader[device_ID], 0):\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                iter_count += 1\n",
    "                    \n",
    "                if iter_count == stopping_iter:\n",
    "                    break\n",
    "            \n",
    "            if np.random.binomial(1, FAULT_RATE) == 1:\n",
    "                print('transmission fault!')\n",
    "                para_set[device_ID] = copy.deepcopy(para)\n",
    "            else:\n",
    "                para_set[device_ID] = copy.deepcopy(net.state_dict())\n",
    "                    \n",
    "            para_set[device_ID] = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    # aggregate the updated models from the selected edge devices (cloud-server side)\n",
    "    para_update = average_state_dic([para_set[i] for i in ACTIVE_DEVICE])\n",
    "    for i in range(DEVICE_NUM):\n",
    "        para_set[i] = copy.deepcopy(para_update)\n",
    "    \n",
    "    # check the performance on the test dataset\n",
    "    net.load_state_dict(para_update)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            if torch.cuda.device_count() != 0:\n",
    "                images, labels = data[0].cuda(), data[1].cuda()\n",
    "            else:\n",
    "                images, labels = data[0], data[1]\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('[%d, %d] test accuracy: %.2f %%' %  (num_epochs + 1, epoch + 1, 100 * float(correct) / total))\n",
    "        \n",
    "#     tested_device = random.randint(0, DEVICE_NUM-1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for decive_ID in range(DEVICE_NUM):\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(testloader_sub[decive_ID], 0):\n",
    "                if torch.cuda.device_count() != 0:\n",
    "                    images, labels = data[0].cuda(), data[1].cuda()\n",
    "                else:\n",
    "                    images, labels = data[0], data[1]\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    print('[%d, %d] average device test accuracy: %.2f %%' % (num_epochs + 1, epoch + 1, 100 * float(correct) / total))\n",
    "            \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ryanenv)",
   "language": "python",
   "name": "ryanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
